---
title: Hue安装及部署
date: 2020-3-5 12:39:21
tags:
 - hue
categories: 大数据
---

# Hue安装及部署

hue官网：http://gethue.com/
配置文档：http://archive.cloudera.com/cdh5/cdh/5/hue-3.9.0-cdh5.16.2
源码：https://github.com/cloudera/hue

这里我们直接用下载Hue：http://archive.cloudera.com/cdh5/cdh/5/hue-3.9.0-cdh5.16.2.tar.gz



## Hue简介

Hue是一个开源的Apache Hadoop UI系统，最早是由Cloudera Desktop演化而来，由Cloudera贡献给开源社区，它是基于Python Web框架Django实现的。通过使用Hue我们可以在浏览器端的Web控制台上与Hadoop集群进行交互来分析处理数据，例如操作HDFS上的数据，运行MapReduce Job等等。很早以前就听说过Hue的便利与强大，一直没能亲自尝试使用，下面先通过官网给出的特性，通过翻译原文简单了解一下Hue所支持的功能特性集合：

- 默认基于轻量级sqlite数据库管理会话数据，用户认证和授权，可以自定义为MySQL、Postgresql，以及Oracle
- 基于文件浏览器（File Browser）访问HDFS
- 基于Hive编辑器来开发和运行Hive查询
- 支持基于Solr进行搜索的应用，并提供可视化的数据视图，以及仪表板（Dashboard）
- 支持基于Impala的应用进行交互式查询
- 支持Spark编辑器和仪表板（Dashboard）
- 支持Pig编辑器，并能够提交脚本任务
- 支持Oozie编辑器，可以通过仪表板提交和监控Workflow、Coordinator和Bundle
- 支持HBase浏览器，能够可视化数据、查询数据、修改HBase表
- 支持Metastore浏览器，可以访问Hive的元数据，以及HCatalog
- 支持Job浏览器，能够访问MapReduce Job（MR1/MR2-YARN）
- 支持Job设计器，能够创建MapReduce/Streaming/Java Job
- 支持Sqoop 2编辑器和仪表板（Dashboard）
- 支持ZooKeeper浏览器和编辑器
- 支持MySql、PostGresql、Sqlite和Oracle数据库查询编辑器



<!-- more -->



## Hue 编译

1.安装系统包

```
sudo yum install ant asciidoc cyrus-sasl-devel cyrus-sasl-gssapi cyrus-sasl-plain gcc gcc-c++ krb5-devel libffi-devel libxml2-devel libxslt-devel make  mysql mysql-devel openldap-devel python-devel sqlite-devel gmp-devel
```

2.编译Hue

```
tar zxf hue-3.9.0-cdh5.16.2.tar.gz -C ~/app/
cd ~/app/hue-3.9.0-cdh5.16.2
make apps
```

当出现类似下面文本时，说明编译成功

```
1426 static files copied to '/home/pearfl/app/hue-3.9.0-cdh5.16.2/build/static', 1426 post-processed.
make[1]: Leaving directory `/home/pearfl/app/hue-3.9.0-cdh5.16.2/apps'
```



## Hue配置

配置文件地址：

```
$HUE_HOME/desktop/conf/hue.ini

[desktop]
	secret_key=23dsafksl;fkp2(随便写，做hash的)
	http_host=hadoop000(跑的机器)
	http_port=38888(8888容易被挖矿，修改)
	time_zone=Asia/Shanghai(时区)

启动HUE
	build/env/bin/supervisor
```



1.HUE整合HDFS

```
core-site.xml

<property>
	<name>hadoop.proxyuser.hadoop.hosts</name>
	<value>*</value>
</property>
<property>
	<name>hadoop.proxyuser.hadoop.groups</name>
	<value>*</value>
</property>
	

hdfs-site.xml

<property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>

修改完Hadoop相关的配置之后，肯定需要重启才生效

hue.ini内修改
[hadoop]
	fs_defaultfs=hdfs://hadoop000:8020
	webhdfs_url=http://hadoop000:50070/webhdfs/v1
	hadoop_conf_dir=$HADOOP_HOME/etc/conf(HADOOP_HOME自己写pwd的那个显示)
```



2.HUE整合MR/YARN

```
你需要启动mr-jobhistory-daemon.sh
	mapred-site.xml
	<property>
		<name>mapreduce.jobhistory.address</name>
		<value>hadoop000:10020</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.webapp.address</name>
		<value>hadoop000:19888</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.done-dir</name>
		<value>/history/done</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.intermediate-done-dir</name>
		<value>/history/done_intermediate</value>
	</property>
	
	mr-jobhistory-daemon.sh start historyserver
		jps进程: JobHistoryServer
	
	[yarn_clusters]
	resourcemanager_host=hadoop000
	resourcemanager_port=8032
	resourcemanager_api_url=http://hadoop000:8088
	proxy_api_url=http://hadoop000:8088
	history_server_api_url=http://hadoop000:19888
	
1.记得yarn已经配置过基础配置了，不然无法启动
2.hue界面的超级用户名字需要和提交到yarn的用户名字相同
```



3.HUE整合MySQL

```
[librdbms]
	打开mysql注释
	nice_name="pearflDB"
	name=demo_hive
	engine=mysql
	host=hadoop000
	port=3306
	user=root
	password=password
```



4.HUE整合Hive

```
一定要先启动hiveserver2
	hiveserver2 1>/dev/null 2>&1 &

	[beeswax]
	hive_server_host=hadoop000
	hive_server_port=10000
	hive_conf_dir=$HIVE_HOME/conf
```



## 补充问题

1.database if locked问题要如何处理？

答：默认底层sqlite3，我们可以配置hue访问mysql



2.Cannot access: /. Note: you are a Hue admin but not a HDFS superuser, "hdfs" or part of HDFS supergroup, "supergroup".

答：hue.ini配置文件中

```
server_user=root
server_group=root
default_user=root
```

