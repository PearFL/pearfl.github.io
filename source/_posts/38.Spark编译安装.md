---
title: Spark编译安装
date: 2020-2-11 10:06:11
tags:
 - spark
 - maven
categories: 大数据
---

## 环境准备

1.JDK:Spark 2.2.0及以上版本只支持JDK1.8

2.Maven：3.6.3

1. 设置maven环境变量时，需设置maven内存：

2. export MAVEN_OPTS=”-Xmx2g -XX:ReservedCodeCacheSize=512m”

3.Scala：2.13.1



## 编译

1. **下载spark的tar包，并解压**

```
# wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.4.5/spark-2.4.5.tgz
# tar -xzvf spark-2.4.5.tgz
```

2. **编辑dev/make-distribution.sh**

```
#  vi dev/make-distribution.sh
```


注释以下内容：

```
#VERSION=$("$MVN" help:evaluate -Dexpression=project.version $@ 2>/dev/null | grep -v "INFO" | tail -n 1)
#SCALA_VERSION=$("$MVN" help:evaluate -Dexpression=scala.binary.version $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | tail -n 1)
#SPARK_HADOOP_VERSION=$("$MVN" help:evaluate -Dexpression=hadoop.version $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | tail -n 1)
#SPARK_HIVE=$("$MVN" help:evaluate -Dexpression=project.activeProfiles -pl sql/hive $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | fgrep --count "<id>hive</id>";\
#    # Reset exit status to 0, otherwise the script stops here if the last grep finds nothing\
#    # because we use "set -o pipefail"
#    echo -n)
```

 添加以下内容：

```
VERSION=2.4.5
SCALA_VERSION=2.13
SPARK_HADOOP_VERSION=2.6.0-cdh5.16.2
SPARK_HIVE=1
```

3. **编辑pom.xml**

 ```
添加

<repository>
    <id>clouders</id>
    <name>clouders Repository</name>
    <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
</repository>
 ```

4. **安装**

   在解压后的spark目录下

```
# $ ./dev/make-distribution.sh --name 2.6.0-cdh5.16.2 --tgz -Dhadoop.version=2.6.0-cdh5.16.2 -Phadoop-2.6 -Phive -Phive-thriftserver -Pyarn
```

