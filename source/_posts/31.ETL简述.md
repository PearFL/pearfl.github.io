---
title: ETL简述
date: 2020-2-9 10:08:44
tags:
 - ETL
 - hadoop
categories: 大数据
---

![31_1](/images/31/31_1.png)

## 为什么要进行ETL

我们使用Flume采集数据到HDFS，从系统架构图来看现在要进行数据的ETL操作，ETL进程对数据进行规范化、验证、清洗，并最终装载进入数据仓库



## 什么是ETL

ETL 即 Extract Transform Load的首字母 ==> 抽取、转换、加载



## ETL该怎么做

数据采集到HDFS上指定的目录下，通过MR写入数据，进行ETL操作，并写出到指定的目录下，ETL操作包括定义数据字段的序列化类，把时间解析出年月日，把URL解析为http、domain和path、对异常值进行处理(try/catch)，使用计数器。



## ETL在服务器上运行需要解决的问题

在本地测试好代码后，上传Jar包到服务器上，跑HDFS上的数据

首先创建三个文件夹lib、data、script放ETL相关的文件，运行脚本的shell文件就在script目录下

由于我们把ETL打的瘦包，所以很多数据需要的依赖Jar包得不到，还有解析库的数据库也需要上传到本地文件下

思路是:



1. 把解析库放到项目的resources目录下
2. 把需要的依赖上传到lib目录下
3. 在`~/.bash_profile`文件下导入LIBJARS路径用来指向lib目录下的依赖

